import streamlit as st
from google import genai
import base64, json, requests
import streamlit.components.v1 as components
import os
import time
 
# ===============================
# è¨­å®š
# ===============================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦3ã¤ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚
 
1ï¸âƒ£ çŸ¥è­˜ãƒ»å®šç¾©ã¯ç›´æ¥ç­”ãˆã‚‹ã€‚
2ï¸âƒ£ æ€è€ƒãƒ»è¨ˆç®—å•é¡Œã¯ç­”ãˆã‚’æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã€‚
3ï¸âƒ£ é€”ä¸­å¼ã‚’è¦‹ã›ã‚‰ã‚ŒãŸå ´åˆã¯æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã€‚
"""
# --- å…±é€šè¨­å®š ---
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore"
MAX_RETRIES = 5
# â˜…ãŠå®¢æ§˜ãŒæŒ‡å®šã—ãŸCSSã«åˆã‚ã›ã¦è¨­å®šã‚’èª¿æ•´
SIDEBAR_FIXED_WIDTH = "450px"
 
# --- APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ ---
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except (KeyError, AttributeError):
    API_KEY = ""
 
# ===============================
# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒå–å¾— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
# ===============================
@st.cache_data
def get_avatar_images():
    base_names = ["yukki-close", "yukki-open"]
    extensions = [".jpg", ".jpeg"]
    loaded_images = {}
    data_uri_prefix = ""
 
    for base in base_names:
        for ext in extensions:
            file_name = base + ext
            try:
                with open(file_name, "rb") as f:
                    loaded_images[base] = base64.b64encode(f.read()).decode("utf-8")
                    data_uri_prefix = f"data:image/{'jpeg' if ext in ['.jpg', '.jpeg'] else 'png'};base64,"
                    break
            except FileNotFoundError:
                continue
 
    if "yukki-close" in loaded_images and "yukki-open" in loaded_images:
        return loaded_images["yukki-close"], loaded_images["yukki-open"], data_uri_prefix, True
    else:
        # ã‚¢ãƒã‚¿ãƒ¼ãŒãªã„å ´åˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼SVG
        placeholder_svg = base64.b64encode(
            f"""<svg width="400" height="400" xmlns="http://www.w3.org/2000/svg"><rect width="100%" height="100%" fill="#f8e7ff"/><text x="50%" y="45%" dominant-baseline="middle" text-anchor="middle" font-size="28" fill="#a00" font-family="sans-serif">âŒç”»åƒãªã—</text><text x="50%" y="55%" dominant-baseline="middle" text-anchor="middle" font-size="20" fill="#a00" font-family="sans-serif">yukki-close/open.jpg/jpeg</text></svg>""".encode('utf-8')
        ).decode("utf-8")
        return placeholder_svg, placeholder_svg, "data:image/svg+xml;base64,", False
 
# ===============================
# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¨Session Stateä¿å­˜ï¼ˆãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯å«ã‚€ï¼‰
# ===============================
def generate_and_store_tts(text):
    """Gemini TTSã§éŸ³å£°ç”Ÿæˆã—ã€base64ãƒ‡ãƒ¼ã‚¿ã‚’st.session_state.audio_to_playã«ä¿å­˜ã™ã‚‹"""
    if not API_KEY:
        st.session_state.audio_to_play = None
        return
       
    payload = {
        "contents": [{"parts": [{"text": text}]}],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig": {"voiceConfig": {"prebuiltVoiceConfig": {"voiceName": TTS_VOICE}}},
        },
        "model": TTS_MODEL,
    }
    headers = {'Content-Type': 'application/json'}
 
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(f"{TTS_API_URL}?key={API_KEY}", headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            result = response.json()
 
            audio_data = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’st.session_stateã«ä¿å­˜
            st.session_state.audio_to_play = audio_data
            return
 
        except requests.exceptions.HTTPError as e:
            if response.status_code in [429, 503] and attempt < MAX_RETRIES - 1:
                time.sleep(2 ** attempt)
                continue
            # æœ€çµ‚è©¦è¡Œã¾ãŸã¯ä»–ã®ã‚¨ãƒ©ãƒ¼
            print(f"API Error (HTTP {response.status_code}) or final attempt failed: {e}")
            break
        except Exception as e:
            print(f"Error generating TTS: {e}")
            break
           
    st.session_state.audio_to_play = None
 
# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼", layout="wide")
 
# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«CSSã®é©ç”¨ (ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå´©ã‚Œã‚’é˜²ããŸã‚ã€æœ€ä½é™ã®èª¿æ•´ã®ã¿æ®‹ã™) ---
st.markdown(f"""
<style>
/* Streamlitã®ãƒ˜ãƒƒãƒ€ãƒ¼/ãƒˆãƒƒãƒ—ãƒãƒ¼ã‚’éè¡¨ç¤ºã«ã™ã‚‹ï¼ˆä»»æ„ï¼‰ */
header {{ visibility: hidden; }}
 
/* â˜…â˜…â˜… ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ›´CSSã®å‰Šé™¤ â˜…â˜…â˜…
.stApp ã«å¯¾ã™ã‚‹ margin-left ã®è¨­å®šã‚’å‰Šé™¤ã—ã€Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«ä¾å­˜ã•ã›ã‚‹ã€‚
*/
 
/* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®ã‚¢ãƒã‚¿ãƒ¼ã‚’ä¸­å¤®ã«é…ç½®ã™ã‚‹ãŸã‚ã®CSS (ãŠå®¢æ§˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ç¶­æŒã—ã€ä¸€éƒ¨æ•´ç†) */
[data-testid="stSidebarContent"] > div:first-child {{
    width: 450px !important;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: flex-start;
}}
.avatar {{
    width: 400px;
    height: 400px;
    border-radius: 16px;
    object-fit: cover;
    /* ãŠå®¢æ§˜ãŒä»¥å‰æŒ‡å®šã•ã‚ŒãŸCSSã‚’ç¶­æŒ */
    margin: 0 auto;
}}
</style>
""", unsafe_allow_html=True)
 
 
# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
if "client" not in st.session_state:
    st.session_state.client = genai.Client(api_key=API_KEY) if API_KEY else None
if "chat" not in st.session_state:
    if st.session_state.client:
        config = {"system_instruction": SYSTEM_PROMPT, "temperature": 0.2}
        st.session_state.chat = st.session_state.client.chats.create(model="gemini-2.5-flash", config=config)
    else:
        st.session_state.chat = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "audio_to_play" not in st.session_state:
    st.session_state.audio_to_play = None
 
# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¢ãƒã‚¿ãƒ¼ã¨é–¢é€£è¦ç´ ã‚’é…ç½® ---
with st.sidebar:
    img_close_base64, img_open_base64, data_uri_prefix, has_images = get_avatar_images()
   
    # ç”»åƒãŒãªã‘ã‚Œã°è­¦å‘Šã‚’è¡¨ç¤º
    if not has_images:
        st.warning("âš ï¸ ã‚¢ãƒã‚¿ãƒ¼ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆyukki-close.jpg/jpeg, yukki-open.jpg/jpegï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
 
    # ãŠå®¢æ§˜ãŒæç¤ºã•ã‚ŒãŸã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆCSSã¨ã‚¢ãƒã‚¿ãƒ¼ã‚’æç”»
    st.markdown(f"""
    <style>
    /* â˜…â˜…â˜… ãŠå®¢æ§˜ãŒã€Œå®Œç’§ã€ã¨æŒ‡å®šã•ã‚ŒãŸCSSã‚’å†åº¦ã“ã“ã«é…ç½® â˜…â˜…â˜… */
    section[data-testid="stSidebar"] {{
        width: 450px !important;
        min-width: {SIDEBAR_FIXED_WIDTH} !important;
        max-width: {SIDEBAR_FIXED_WIDTH} !important;
        background-color: #FFFFFF !important;
    }}
    .main {{ background-color: #FFFFFF !important; }}
    .st-emotion-cache-1y4p8pa {{
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        height: 100vh;
    }}
    .avatar {{ width: 400px; height: 400px; border-radius: 16px; object-fit: cover; }}
    </style>
    <img id="avatar" src="{data_uri_prefix}{img_close_base64}" class="avatar">
   
    <script>
    const imgCloseBase64 = "{data_uri_prefix}{img_close_base64}";
    const imgOpenBase64 = "{data_uri_prefix}{img_open_base64}";
    let talkingInterval = null;
   
    window.startTalking = function() {{
        const avatar = document.getElementById('avatar');
        if ({'true' if has_images else 'false'} && avatar) {{
            let toggle = false;
            if (talkingInterval) clearInterval(talkingInterval);
            talkingInterval = setInterval(() => {{
                avatar.src = toggle ? imgOpenBase64 : imgCloseBase64;
                toggle = !toggle;
            }}, 160);
        }}
    }}
   
    window.stopTalking = function() {{
        if (talkingInterval) clearInterval(talkingInterval);
        const avatar = document.getElementById('avatar');
        if ({'true' if has_images else 'false'} && avatar) {{
            avatar.src = imgCloseBase64;
        }}
    }}
    </script>
    """, unsafe_allow_html=True)
 
# --- éŸ³å£°å†ç”Ÿãƒˆãƒªã‚¬ãƒ¼ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¿½åŠ ï¼ˆå£ãƒ‘ã‚¯åˆ¶å¾¡ã¨WAVå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆï¼‰ ---
if st.session_state.audio_to_play:
    # WAVå¤‰æ›ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å®šç¾©ã—ãŸJavaScriptã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥
    js_code = f"""
    <script>
        // --- PCM to WAV Utility Functions ---
        function base64ToArrayBuffer(base64) {{
            const binary_string = window.atob(base64);
            const len = binary_string.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {{ bytes[i] = binary_string.charCodeAt(i); }}
            return bytes.buffer;
        }}
        function writeString(view, offset, string) {{
            for (let i = 0; i < string.length; i++) {{ view.setUint8(offset + i, string.charCodeAt(i)); }}
        }}
        function pcmToWav(pcmData, sampleRate) {{
            const numChannels = 1; const bitsPerSample = 16;
            const bytesPerSample = bitsPerSample / 8; const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign; const dataSize = pcmData.byteLength;
            const buffer = new ArrayBuffer(44 + dataSize); const view = new DataView(buffer); let offset = 0;
 
            writeString(view, offset, 'RIFF'); offset += 4;
            view.setUint32(offset, 36 + dataSize, true); offset += 4;
            writeString(view, offset, 'WAVE'); offset += 4;
            writeString(view, offset, 'fmt '); offset += 4;
            view.setUint32(offset, 16, true); offset += 4;
            view.setUint16(offset, 1, true); offset += 2;
            view.setUint16(offset, numChannels, true); offset += 2;
            view.setUint32(offset, sampleRate, true); offset += 4;
            view.setUint32(offset, byteRate, true); offset += 4;
            view.setUint16(offset, blockAlign, true); offset += 2;
            view.setUint16(offset, bitsPerSample, true); offset += 2;
            writeString(view, offset, 'data'); offset += 4;
            view.setUint32(offset, dataSize, true); offset += 4;
 
            const pcm16 = new Int16Array(pcmData);
            for (let i = 0; i < pcm16.length; i++) {{ view.setInt16(offset, pcm16[i], true); offset += 2; }}
            return new Blob([buffer], {{ type: 'audio/wav' }});
        }}
 
        // --- å†ç”Ÿãƒ­ã‚¸ãƒƒã‚¯ ---
        const base64AudioData = '{st.session_state.audio_to_play}';
        const sampleRate = 24000; // Gemini TTSã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆPCMãƒ¬ãƒ¼ãƒˆ
       
        if (window.startTalking) window.startTalking();
       
        const pcmData = base64ToArrayBuffer(base64AudioData);
        const wavBlob = pcmToWav(pcmData, sampleRate);
        const audioUrl = URL.createObjectURL(wavBlob);
       
        const audio = new Audio(audioUrl);
        audio.autoplay = true;
 
        audio.onended = () => {{ if (window.stopTalking) window.stopTalking(); }};
        audio.play().catch(e => {{
            console.error("Audio playback failed:", e);
            if (window.stopTalking) window.stopTalking();
        }});
    </script>
    """
    components.html(js_code, height=0, width=0)
    # å†ç”Ÿãƒˆãƒªã‚¬ãƒ¼å®Ÿè¡Œå¾Œã€ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    st.session_state.audio_to_play = None
 
# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
st.title("ğŸ€ ãƒ¦ãƒƒã‚­ãƒ¼")
st.caption("çŸ¥è­˜ã¯ç­”ãˆã€æ€è€ƒã¯è§£æ³•ã‚¬ã‚¤ãƒ‰ã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚")
 
# éŸ³å£°èªè­˜ãƒœã‚¿ãƒ³ã¨ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
st.subheader("éŸ³å£°å…¥åŠ›")
components.html("""
<div id="mic-container" style="padding: 10px 0;">
    <button onclick="window.parent.startRec()"
            style="background-color: #ff69b4; color: white; border: none; padding: 10px 20px; border-radius: 8px; cursor: pointer; font-size: 16px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
        ğŸ™ è©±ã™
    </button>
    <p id="mic-status" style="margin-top: 10px;">ãƒã‚¤ã‚¯åœæ­¢ä¸­</p>
</div>
<script>
// Streamlitã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã™ã‚‹é–¢æ•°
function sendTextToStreamlit(text) {
    window.parent.postMessage({
        type: 'SET_CHAT_INPUT',
        text: text
    }, '*');
}
 
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
let recognition;
 
if (SpeechRecognition) {
    recognition = new SpeechRecognition();
    recognition.lang = 'ja-JP';
    recognition.continuous = false;
    recognition.interimResults = false;
   
    // ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªèªè­˜é–‹å§‹é–¢æ•° (Streamlitå´ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹)
    window.parent.startRec = () => {
        document.getElementById("mic-status").innerText = "ğŸ§ è´ãå–ã‚Šä¸­...";
        recognition.start();
    };
   
    recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        document.getElementById("mic-status").innerText = "âœ… " + text;
        sendTextToStreamlit(text);
    };
   
    recognition.onerror = (e) => {
        document.getElementById("mic-status").innerText = "âš ï¸ ã‚¨ãƒ©ãƒ¼: " + e.error;
    };
   
    recognition.onend = () => {
        if (document.getElementById("mic-status").innerText.startsWith("ğŸ§")) {
            document.getElementById("mic-status").innerText = "ãƒã‚¤ã‚¯åœæ­¢ä¸­";
        }
    };
} else {
    document.getElementById("mic-container").innerHTML = "ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚";
}
</script>
""", height=130)
 
st.subheader("ãƒ¦ãƒƒã‚­ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´")
for msg in st.session_state.messages:
    avatar_icon = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar_icon):
        st.markdown(msg["content"])
 
# --- ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¨å‡¦ç† ---
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ãƒ»è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
   
    # 2. ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å–å¾—ãƒ»è¡¨ç¤º
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("ãƒ¦ãƒƒã‚­ãƒ¼ãŒæ€è€ƒä¸­..."):
            if st.session_state.chat:
                try:
                    # Gemini APIå‘¼ã³å‡ºã—
                    response = st.session_state.chat.send_message(prompt)
                    text = response.text
                   
                    # å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
                    st.markdown(text)
                   
                    # 3. éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                    generate_and_store_tts(text)
                   
                    # 4. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                    st.session_state.messages.append({"role": "assistant", "content": text})
 
                except Exception as e:
                    error_msg = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
            else:
                st.session_state.messages.append({"role": "assistant", "content": "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"})
   
    # Rerunã‚’å®Ÿè¡Œã—ã€UIã‚’æ›´æ–°
    st.rerun()
 
# --- éŸ³å£°èªè­˜ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¸ãƒ†ã‚­ã‚¹ãƒˆã‚’è»¢é€ã™ã‚‹JavaScript ---
components.html("""
<script>
window.addEventListener('message', event => {
    if (event.data.type === 'SET_CHAT_INPUT') {
        const chatInput = window.parent.document.querySelector('textarea[data-testid="stChatInputTextArea"]');
        if (chatInput) {
            chatInput.value = event.data.text;
            chatInput.dispatchEvent(new Event('input', { bubbles: true }));
            const enterEvent = new KeyboardEvent('keydown', { key: 'Enter', bubbles: true, keyCode: 13 });
            chatInput.dispatchEvent(enterEvent);
        }
    }
});
</script>
""", height=0)
 
 
 