import streamlit as st
from google import genai
import base64, json, requests
import streamlit.components.v1 as components
import os
import time

# ===============================
# è¨­å®š
# ===============================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦3ã¤ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚
 
1ï¸âƒ£ çŸ¥è­˜ãƒ»å®šç¾©ã¯ç›´æ¥ç­”ãˆã‚‹ã€‚
2ï¸âƒ£ æ€è€ƒãƒ»è¨ˆç®—å•é¡Œã¯ç­”ãˆã‚’æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã€‚
3ï¸âƒ£ é€”ä¸­å¼ã‚’è¦‹ã›ã‚‰ã‚ŒãŸå ´åˆã¯æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã€‚
"""
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore" # éŸ³å£°ãƒ¢ãƒ‡ãƒ«ï¼ˆç”·æ€§çš„ãªå£°ï¼‰
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = ""
 
# ===============================
# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒå–å¾— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
# *æŠ€è¡“çš„åˆ¶ç´„ã«ã‚ˆã‚Šã€ä»»æ„ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.mp4ãªã©ï¼‰ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ TTSã¨åŒæœŸã•ã›ã‚‹ã“ã¨ã¯å›°é›£ã§ã™ã€‚
# *ãã®ãŸã‚ã€æœ¬ã‚¢ãƒ—ãƒªã§ã¯2æšã®ç”»åƒåˆ‡æ›¿ã«ã‚ˆã‚‹ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚
# ===============================
@st.cache_data
def get_avatar_images():
    loaded_images = {}
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç‰¹å®šã®ç”»åƒï¼ˆyukki-closed.jpg, yukki-open.jpgï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚Œã°ãã‚Œã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã§ãã¾ã™ãŒã€
    # ç¢ºå®Ÿãªå‹•ä½œã®ãŸã‚ã€ã“ã“ã§ã¯å¸¸ã«å‹•ä½œã™ã‚‹ãƒ€ãƒŸãƒ¼ã®Base64 SVGç”»åƒã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
    
    # å£é–‰ã˜ã®ç”»åƒ (é’è‰²ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼)
    closed_svg = f"""<svg width="200" height="200" xmlns="http://www.w3.org/2000/svg"><rect width="200" height="200" fill="#4a90e2"/><text x="100" y="100" font-size="20" fill="white" text-anchor="middle" dominant-baseline="middle">Yukki (é–‰)</text></svg>"""
    loaded_images["closed"] = "data:image/svg+xml;base64," + base64.b64encode(closed_svg.encode('utf-8')).decode('utf-8')

    # å£é–‹ãã®ç”»åƒ (ç·‘è‰²ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼)
    open_svg = f"""<svg width="200" height="200" xmlns="http://www.w3.org/2000/svg"><rect width="200" height="200" fill="#32a852"/><text x="100" y="100" font-size="20" fill="white" text-anchor="middle" dominant-baseline="middle">Yukki (é–‹)</text></svg>"""
    loaded_images["open"] = "data:image/svg+xml;base64," + base64.b64encode(open_svg.encode('utf-8')).decode('utf-8')
    
    return loaded_images

# ===============================
# TTSå‡¦ç†ï¼ˆéŸ³å£°ç”Ÿæˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆä¿å­˜ï¼‰
# ===============================
def generate_and_store_tts(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰TTSãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã™ã‚‹"""
    if not API_KEY:
        st.session_state.tts_data = None
        return

    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã‚’ç”¨ã„ãŸAPIå‘¼ã³å‡ºã—
    MAX_RETRIES = 3
    RETRY_DELAY = 1

    for attempt in range(MAX_RETRIES):
        payload = {
            "contents": [{
                "parts": [{"text": text}]
            }],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": {
                    "voiceConfig": {
                        "prebuiltVoiceConfig": {"voiceName": TTS_VOICE}
                    }
                }
            },
            "model": TTS_MODEL
        }

        headers = {'Content-Type': 'application/json'}
        params = {'key': API_KEY}
        
        try:
            response = requests.post(TTS_API_URL, headers=headers, params=params, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            
            audio_part = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0]
            audio_data = audio_part.get('inlineData', {}).get('data')
            mime_type = audio_part.get('inlineData', {}).get('mimeType')
            
            if audio_data and mime_type:
                st.session_state.tts_data = {
                    "audio_data": audio_data,
                    "mime_type": mime_type
                }
                return # æˆåŠŸã—ãŸã‚‰çµ‚äº†
            else:
                st.session_state.tts_data = None
                st.error("TTSå¿œç­”ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return # å¤±æ•—ã—ãŸã‚‰çµ‚äº† (ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡å¤–)

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY * (2 ** attempt))
            else:
                st.error(f"TTS APIã‚¨ãƒ©ãƒ¼: {e}")
                st.session_state.tts_data = None


# ===============================
# TTSã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³UI
# ===============================
def talking_avatar_ui(images):
    """TTSãƒ‡ãƒ¼ã‚¿ã¨é€£å‹•ã—ã¦ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã‚¢ãƒã‚¿ãƒ¼ã¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’é…ç½®ã™ã‚‹"""
    
    if not images:
        return
    
    # HTML/JavaScriptã‚’è¨˜è¿°
    html_content = f"""
    <style>
        .avatar-container {{
            text-align: center;
            padding: 1rem;
            border-radius: 12px;
            background-color: #f0f2f6;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }}
        #avatar-image {{
            width: 150px;
            height: 150px;
            border-radius: 50%;
            object-fit: cover;
            border: 4px solid #4a90e2;
            transition: transform 0.1s ease;
        }}
        #audio-player {{
            display: none; /* ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è‡ªä½“ã¯éè¡¨ç¤º */
        }}
        .status-text {{
            margin-top: 0.5rem;
            font-size: 1rem;
            color: #333;
        }}
    </style>
    <div class="avatar-container">
        <img id="avatar-image" src="{images['closed']}" alt="Yukki Avatar">
        <div class="status-text" id="status-text">æº–å‚™å®Œäº†</div>
        <audio id="audio-player" controls preload="auto"></audio>
    </div>

    <script>
        const audioPlayer = document.getElementById('audio-player');
        const avatarImage = document.getElementById('avatar-image');
        const statusText = document.getElementById('status-text');
        const closedImgSrc = "{images['closed']}";
        const openImgSrc = "{images['open']}";
        let animationInterval = null;

        // PCMãƒ‡ãƒ¼ã‚¿ã‚’WAVã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
        function base64ToArrayBuffer(base64) {{
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {{
                bytes[i] = binaryString.charCodeAt(i);
            }}
            return bytes.buffer;
        }}

        function pcmToWav(pcm16, sampleRate) {{
            const pcmData = pcm16.buffer;
            const numChannels = 1;
            const bytesPerSample = 2; // Int16
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = pcmData.byteLength;
            const chunkSize = 36 + dataSize;

            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);

            let offset = 0;

            // RIFF chunk
            function writeString(s) {{
                for (let i = 0; i < s.length; i++) {{
                    view.setUint8(offset++, s.charCodeAt(i));
                }}
            }}

            writeString('RIFF'); // Chunk ID
            view.setUint32(offset, chunkSize, true); offset += 4; // Chunk size
            writeString('WAVE'); offset += 4; // Format

            // FMT sub-chunk
            writeString('fmt '); offset += 4; // Sub-chunk 1 ID
            view.setUint32(offset, 16, true); offset += 4; // Sub-chunk 1 size (16 for PCM)
            view.setUint16(offset, 1, true); offset += 2; // Audio format (1 for PCM)
            view.setUint16(offset, numChannels, true); offset += 2; // Number of channels
            view.setUint32(offset, sampleRate, true); offset += 4; // Sample rate
            view.setUint32(offset, byteRate, true); offset += 4; // Byte rate
            view.setUint16(offset, blockAlign, true); offset += 2; // Block align
            view.setUint16(offset, 16, true); offset += 2; // Bits per sample (16 bit)

            // DATA sub-chunk
            writeString('data'); offset += 4; // Sub-chunk 2 ID
            view.setUint32(offset, dataSize, true); offset += 4; // Sub-chunk 2 size

            // PCM data
            const pcmView = new Int16Array(pcmData);
            for (let i = 0; i < pcmView.length; i++) {{
                view.setInt16(offset, pcmView[i], true); offset += 2;
            }}

            return new Blob([view], {{ type: 'audio/wav' }});
        }}
        
        // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
        function startAnimation() {{
            let isOpen = true;
            statusText.textContent = "ãƒ¦ãƒƒã‚­ãƒ¼ãŒè©±ã—ã¦ã„ã¾ã™...";
            avatarImage.style.transform = 'scale(1.05)'; // è©±ã—å§‹ã‚ã«å°‘ã—æ‹¡å¤§

            animationInterval = setInterval(() => {{
                if (isOpen) {{
                    avatarImage.src = openImgSrc;
                }} else {{
                    avatarImage.src = closedImgSrc;
                }}
                isOpen = !isOpen;
            }}, 120); // 120msã”ã¨ã«ç”»åƒã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹

            audioPlayer.play();
        }}

        function stopAnimation() {{
            clearInterval(animationInterval);
            animationInterval = null;
            avatarImage.src = closedImgSrc;
            statusText.textContent = "æº–å‚™å®Œäº†";
            avatarImage.style.transform = 'scale(1.0)';
        }}

        // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
        audioPlayer.onplay = startAnimation;
        audioPlayer.onended = stopAnimation;
        audioPlayer.onerror = function() {{
            console.error("Audio playback error.");
            stopAnimation();
        }};
        
        // Streamlitã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ã€éŸ³å£°ã‚’å†ç”Ÿ
        window.addEventListener('message', event => {{
            if (event.data.type === 'PLAY_TTS' && event.data.audioBase64) {{
                const audioData = event.data.audioBase64;
                const mimeType = event.data.mimeType || 'audio/L16;rate=24000';
                
                // MIMEã‚¿ã‚¤ãƒ—ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã‚’æŠ½å‡º
                const rateMatch = mimeType.match(/rate=(\d+)/);
                const sampleRate = rateMatch ? parseInt(rateMatch[1], 10) : 24000;
                
                // PCM16ãƒ‡ãƒ¼ã‚¿ã‚’WAVå½¢å¼ã«å¤‰æ›
                const pcmData = base64ToArrayBuffer(audioData);
                const pcm16 = new Int16Array(pcmData);
                const wavBlob = pcmToWav(pcm16, sampleRate);
                
                // Blob URLã‚’ä½œæˆã—ã€Audioè¦ç´ ã«è¨­å®š
                const audioUrl = URL.createObjectURL(wavBlob);
                audioPlayer.src = audioUrl;
                
                // å†ç”Ÿé–‹å§‹ï¼ˆonplayã‚¤ãƒ™ãƒ³ãƒˆã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãŒé–‹å§‹ã•ã‚Œã‚‹ï¼‰
                // audioPlayer.load(); // ä¸è¦ãªå ´åˆãŒå¤šã„
                audioPlayer.play().catch(e => console.error("Auto-play failed:", e));
            }}
        }});
    </script>
    """
    
    # UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨ã—ã¦è¡¨ç¤º
    components.html(html_content, height=200)

# ===============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===============================
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼å…ˆç”Ÿ", layout="wide")

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.title("ğŸ¤– ãƒ¦ãƒƒã‚­ãƒ¼å…ˆç”Ÿï¼šéŸ³å£°é€£å‹•AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.markdown("è³ªå•ã‚’å…¥åŠ›ã¾ãŸã¯éŸ³å£°ã§è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚ãƒ¦ãƒƒã‚­ãƒ¼ãŒéŸ³å£°ã¨ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã§å¿œç­”ã—ã¾ã™ã€‚")

# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒã®ãƒ­ãƒ¼ãƒ‰
avatar_images = get_avatar_images()

# --- TTSã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³UIã®é…ç½® ---
talking_avatar_ui(avatar_images)

# --- Streamlitã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "client" not in st.session_state:
    if API_KEY:
        # APIã‚­ãƒ¼ãŒç©ºã§ãªã„å ´åˆã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        st.session_state.client = genai.Client(api_key=API_KEY)
    else:
        st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

if "chat" not in st.session_state and API_KEY:
    config = {"system_instruction": SYSTEM_PROMPT, "temperature": 0.2}
    st.session_state.chat = st.session_state.client.chats.create(model='gemini-2.5-flash', config=config)

if "messages" not in st.session_state:
    st.session_state.messages = []

# TTSå†ç”Ÿãƒ•ãƒ©ã‚°ã®åˆæœŸåŒ–
if 'tts_data' not in st.session_state:
    st.session_state.tts_data = None
    
# --- éŸ³å£°èªè­˜UIã®é…ç½® ---
# (éŸ³å£°èªè­˜UIã¯å‰å›ã®ã‚‚ã®ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¾ã™)
speech_to_text_html = """
<div id="mic-container" style="text-align: center; margin-top: 10px;">
    <button id="mic-button" style="padding: 10px 20px; font-size: 16px; background-color: #4a90e2; color: white; border: none; border-radius: 8px; cursor: pointer; box-shadow: 0 4px #2a70c2;">
        ğŸ™ï¸ éŸ³å£°å…¥åŠ›é–‹å§‹
    </button>
</div>

<script>
const micButton = document.getElementById('mic-button');
const micContainer = document.getElementById('mic-container');
let recognition = null;

if ('webkitSpeechRecognition' in window) {
    recognition = new webkitSpeechRecognition();
    recognition.continuous = false; // ç™ºè©±ã®åº¦ã«åœæ­¢
    recognition.lang = 'ja-JP';

    micButton.onclick = () => {
        if (recognition) {
            micButton.textContent = 'ğŸ”´ éŒ²éŸ³ä¸­...';
            micButton.style.backgroundColor = '#d9534f';
            micButton.style.boxShadow = '0 4px #a03c39';
            recognition.start();
        }
    };

    recognition.onresult = (event) => {
        const result = event.results[0][0].transcript;
        // Streamlitã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
        window.parent.postMessage({
            type: 'SET_CHAT_INPUT',
            text: result
        }, '*');
    };

    recognition.onend = () => {
        micButton.textContent = 'ğŸ™ï¸ éŸ³å£°å…¥åŠ›é–‹å§‹';
        micButton.style.backgroundColor = '#4a90e2';
        micButton.style.boxShadow = '0 4px #2a70c2';
    };

    recognition.onerror = (event) => {
        micButton.textContent = 'ã‚¨ãƒ©ãƒ¼: ' + event.error;
        micButton.style.backgroundColor = '#f0ad4e';
        micButton.style.boxShadow = '0 4px #d49a3e';
    };

} else {
    micContainer.innerHTML = "<p style='color:red;'>ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚</p>";
}
</script>
"""
components.html(speech_to_text_html, height=100)

st.subheader("ãƒ¦ãƒƒã‚­ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´")

# --- ä¼šè©±å±¥æ­´è¡¨ç¤º ---
for msg in st.session_state.messages:
    # ã‚¢ãƒã‚¿ãƒ¼ã®ã‚¢ã‚¤ã‚³ãƒ³ã¯å›ºå®š
    avatar = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
 
# --- ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¨å‡¦ç† --
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ç”Ÿæˆ
    if st.session_state.get("chat"):
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.spinner("æ€è€ƒä¸­..."):
                response = st.session_state.chat.send_message(prompt)
                text = response.text
                st.markdown(text)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": text})
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            generate_and_store_tts(text)
            
    else:
        st.session_state.messages.append({"role": "assistant", "content": "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"})
    
    st.rerun()

# --- éŸ³å£°èªè­˜ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¸ãƒ†ã‚­ã‚¹ãƒˆã‚’è»¢é€ã™ã‚‹JavaScript ---
components.html("""
<script>
window.addEventListener('message', event => {
    if (event.data.type === 'SET_CHAT_INPUT') {
        // Streamlitã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›è¦ç´ ã‚’è¦‹ã¤ã‘ã¦å€¤ã‚’è¨­å®šã™ã‚‹
        const chatInput = window.parent.document.querySelector('input[placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."]');
        if (chatInput) {
            chatInput.value = event.data.text;
            
            // ã‚¨ãƒ³ã‚¿ãƒ¼ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºç«ã•ã›ã¦å…¥åŠ›ã‚’ç¢ºå®šã•ã›ã‚‹
            const event = new KeyboardEvent('keydown', {
                key: 'Enter',
                keyCode: 13,
                which: 13,
                bubbles: true
            });
            chatInput.dispatchEvent(event);
        }
    }
});
</script>
""", height=0)


# --- TTSå†ç”Ÿãƒˆãƒªã‚¬ãƒ¼ ---
if st.session_state.get('tts_data'):
    # JavaScriptã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚¹ãƒˆã—ã¦å†ç”Ÿã‚’ãƒˆãƒªã‚¬ãƒ¼
    js_trigger = f"""
    <script>
    const ttsData = {{
        type: 'PLAY_TTS',
        audioBase64: '{st.session_state['tts_data']['audio_data']}',
        mimeType: '{st.session_state['tts_data']['mime_type']}'
    }};
    
    // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³UIã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹iframeã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
    const iframes = window.parent.document.querySelectorAll('iframe');
    iframes.forEach(iframe => {{
        iframe.contentWindow.postMessage(ttsData, '*');
    }});
    </script>
    """
    components.html(js_trigger, height=0)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€å†å®Ÿè¡Œã‚’é˜²ã
    del st.session_state['tts_data']

# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’æœ€å¾Œã«è¡¨ç¤º (ä»Šå›ã¯ãƒ€ãƒŸãƒ¼ç”»åƒã§å›é¿æ¸ˆã¿)
if not avatar_images:
    st.error("ã‚¢ãƒã‚¿ãƒ¼ç”»åƒã‚’æ­£ã—ãè¨­å®šã™ã‚‹ã‹ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
