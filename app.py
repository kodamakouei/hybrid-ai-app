import streamlit as st
from google import genai
import base64, json, requests
import streamlit.components.v1 as components
import os

# ===============================
# è¨­å®š
# ===============================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦3ã¤ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚

1ï¸âƒ£ çŸ¥è­˜ãƒ»å®šç¾©ã¯ç›´æ¥ç­”ãˆã‚‹ã€‚
2ï¸âƒ£ æ€è€ƒãƒ»è¨ˆç®—å•é¡Œã¯ç­”ãˆã‚’æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã€‚
3ï¸âƒ£ é€”ä¸­å¼ã‚’è¦‹ã›ã‚‰ã‚ŒãŸå ´åˆã¯æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã€‚
"""
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore"
# NOTE: APIã‚­ãƒ¼ã¯Streamlitã®st.secretsã‹ã‚‰å–å¾—ã™ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚
API_KEY = st.secrets["GEMINI_API_KEY"] 

# ===============================
# ã‚¢ãƒã‚¿ãƒ¼è¡¨ç¤ºï¼ˆå£ãƒ‘ã‚¯ä»˜ãï¼‰
# ===============================
def show_avatar():
    # â˜…å®Ÿè¡Œç’°å¢ƒã« yukki-close.jpg ã¨ yukki-open.jpg ãŒå¿…è¦ã§ã™
    if not (os.path.exists("yukki-close.jpg") and os.path.exists("yukki-open.jpg")):
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¦åœæ­¢
        st.error("âŒ yukki-close.jpg ã¨ yukki-open.jpg ãŒåŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    # base64ã«å¤‰æ›ã—ã¦HTML/JSã«åŸ‹ã‚è¾¼ã‚€
    with open("yukki-close.jpg", "rb") as f:
        img_close = base64.b64encode(f.read()).decode("utf-8")
    with open("yukki-open.jpg", "rb") as f:
        img_open = base64.b64encode(f.read()).decode("utf-8")

    # Streamlitã«HTML/JSã‚’åŸ‹ã‚è¾¼ã¿ï¼ˆå£ãƒ‘ã‚¯åˆ¶å¾¡ï¼‰
    components.html(f"""
    <style>
    .avatar {{
        width: 280px;
        height: 280px;
        border-radius: 16px;
        border: 2px solid #f0a;
        object-fit: cover;
    }}
    </style>
    <div style="text-align:center;">
      <img id="avatar" src="data:image/jpeg;base64,{img_close}" class="avatar">
    </div>

    <script>
    // å£ãƒ‘ã‚¯é–‹å§‹é–¢æ•°
    let talkingInterval = null;
    function startTalking() {{
        const avatar = document.getElementById('avatar');
        let toggle = false;
        if (talkingInterval) clearInterval(talkingInterval);
        talkingInterval = setInterval(() => {{
            avatar.src = toggle
              ? "data:image/jpeg;base64,{img_open}" // å£ãŒé–‹ã„ãŸç”»åƒ
              : "data:image/jpeg;base64,{img_close}"; // å£ãŒé–‰ã˜ãŸç”»åƒ
            toggle = !toggle;
        }}, 160); // ãƒ‘ã‚¯ãƒ‘ã‚¯é€Ÿåº¦ï¼ˆãƒŸãƒªç§’ï¼‰
    }}
    // å£ãƒ‘ã‚¯åœæ­¢é–¢æ•°
    function stopTalking() {{
        clearInterval(talkingInterval);
        const avatar = document.getElementById('avatar');
        avatar.src = "data:image/jpeg;base64,{img_close}";
    }}
    </script>
    """, height=340)

# ===============================
# éŸ³å£°å†ç”Ÿï¼‹å£ãƒ‘ã‚¯åˆ¶å¾¡ (ä¿®æ­£æ¸ˆã¿)
# ===============================
def play_tts_with_lip(text):
    # Gemini TTS APIã¸ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ§‹ç¯‰
    payload = {
        "contents": [{"parts": [{"text": text}]}],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig": {"voiceConfig": {"prebuiltVoiceConfig": {"voiceName": TTS_VOICE}}}
        },
        "model": TTS_MODEL
    }
    
    headers = {'Content-Type': 'application/json'}
    
    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ãã®APIå‘¼ã³å‡ºã—
    MAX_RETRIES = 5
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(f"{TTS_API_URL}?key={API_KEY}", headers=headers, data=json.dumps(payload))
            response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
            result = response.json()
            break
        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                import time
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                st.error(f"âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
                return

    try:
        # resultã‹ã‚‰base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º (ãƒ‡ã‚³ãƒ¼ãƒ‰ã›ãšãã®ã¾ã¾ä½¿ç”¨)
        audio_data_base64 = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
    except Exception:
        st.error("âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ãŒäºˆæœŸã•ã‚ŒãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ğŸ¬ JavaScriptã§å£ãƒ‘ã‚¯ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ã¨è‡ªå‹•å†ç”Ÿ
    # st.audioã‚’ä½¿ã‚ãšã€HTML/JSã§ <audio autoplay> ã‚’ç”Ÿæˆã—ã€onendedã§å£ãƒ‘ã‚¯ã‚’åœæ­¢ã•ã›ã‚‹
    html_audio_player = f"""
    <script>
    // window.startTalkingã¨window.stopTalkingã¯show_avatar()ã§å®šç¾©ã•ã‚Œã¦ã„ã¾ã™
    if (window.startTalking) startTalking();
    
    // Audioã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆã—ã€Base64ãƒ‡ãƒ¼ã‚¿URIã‚’è¨­å®š
    const audio = new Audio();
    // TTS APIã¯PCM16ã‚’è¿”ã™ãŸã‚ã€ã“ã“ã§ã¯ 'audio/wav' ã¨ã—ã¦Base64ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã„ã¾ã™
    audio.src = 'data:audio/wav;base64,{audio_data_base64}'; 
    audio.autoplay = true;

    // éŸ³å£°å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰å£ãƒ‘ã‚¯ã‚’åœæ­¢
    audio.onended = function() {{
        if (window.stopTalking) stopTalking();
    }};
    
    // è‡ªå‹•å†ç”Ÿã‚’è©¦ã¿ã‚‹ (ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒãƒªã‚·ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹)
    audio.play().catch(e => {{
        console.error("Audio playback failed (usually due to autoplay policy):", e);
        // å†ç”Ÿã«å¤±æ•—ã—ãŸå ´åˆã§ã‚‚ã€å£ãƒ‘ã‚¯ã‚’åœæ­¢ã•ã›ã‚‹
        if (window.stopTalking) stopTalking(); 
    }});

    // Streamlitã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’å†ç”Ÿã•ã›ã‚‹ãŸã‚ã€
    // UIã‹ã‚‰ã¯è¦‹ãˆãªã„ä½ç½®ã«ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¦ç´ ã‚’ä¸€æ™‚çš„ã«æŒ¿å…¥ (ãŸã ã—ã€è‡ªå‹•å†ç”Ÿã®å›é¿ç­–ã¨ã—ã¦æ©Ÿèƒ½ã—ãªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™)
    const container = document.createElement('div');
    container.style.display = 'none';
    container.appendChild(audio);
    document.body.appendChild(container);
    </script>
    """
    # components.htmlã§ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå†ç”Ÿã¨å£ãƒ‘ã‚¯åˆ¶å¾¡ã‚’åŒæ™‚ã«è¡Œã†
    # height=0, width=0ã«è¨­å®šã™ã‚‹ã“ã¨ã§ã€ã“ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè‡ªä½“ã‚’éè¡¨ç¤ºã«ã—ã¾ã™
    components.html(html_audio_player, height=0, width=0)

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆå£ãƒ‘ã‚¯å¯¾å¿œï¼‰", layout="wide")
st.title("ğŸ€ ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆVtuberé¢¨AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼‰")

# ã‚¢ãƒã‚¿ãƒ¼ã®è¡¨ç¤ºã¨JSé–¢æ•°ã®åŸ‹ã‚è¾¼ã¿
show_avatar()

# Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
if "client" not in st.session_state:
    st.session_state.client = genai.Client(api_key=API_KEY)
if "chat" not in st.session_state:
    config = {"system_instruction": SYSTEM_PROMPT, "temperature": 0.2}
    st.session_state.chat = st.session_state.client.chats.create(model="gemini-2.5-flash", config=config)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ===============================
# éŸ³å£°èªè­˜ãƒœã‚¿ãƒ³ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶æ¨™æº–APIï¼‰
# ===============================
# HTML/JSã§ãƒ–ãƒ©ã‚¦ã‚¶ã®SpeechRecognition APIã‚’ä½¿ã„ã€çµæœã‚’Streamlitã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã«æ³¨å…¥ã™ã‚‹
components.html("""
<script>
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
let recognition;

if (SpeechRecognition) {
    recognition = new SpeechRecognition();
    recognition.lang = 'ja-JP'; // æ—¥æœ¬èªã‚’è¨­å®š
    recognition.continuous = false;
    recognition.interimResults = false;

    // èªè­˜é–‹å§‹ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©
    function startRec() {
        document.getElementById("mic-status").innerText = "ğŸ§ è´ãå–ã‚Šä¸­...";
        recognition.start();
    }

    // èªè­˜çµæœãŒå‡ºãŸã¨ãã®ãƒãƒ³ãƒ‰ãƒ©
    recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        document.getElementById("mic-status").innerText = "âœ… " + text;
        
        // Streamlitã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ã‚’æ¢ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æ³¨å…¥
        const chatInput = window.parent.document.querySelector('textarea[data-testid="stChatInputTextArea"]');
        if (chatInput) {
            chatInput.value = text;
            chatInput.dispatchEvent(new Event('input', { bubbles: true })); // inputã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºç«
            
            // ã‚¨ãƒ³ã‚¿ãƒ¼ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºç«ã•ã›ã¦é€ä¿¡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            const enterEvent = new KeyboardEvent('keydown', { key: 'Enter', bubbles: true });
            chatInput.dispatchEvent(enterEvent);
        }
    };

    // èªè­˜ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒãƒ³ãƒ‰ãƒ©
    recognition.onerror = (e) => {
        document.getElementById("mic-status").innerText = "âš ï¸ ã‚¨ãƒ©ãƒ¼: " + e.error;
    };

    // èªè­˜ãŒçµ‚äº†ã—ãŸæ™‚ã®ãƒãƒ³ãƒ‰ãƒ©ï¼ˆç¶šã‘ã¦èªè­˜ã™ã‚‹å ´åˆã¯ã“ã“ã§recognition.start()ã‚’å‘¼ã¶ï¼‰
    recognition.onend = () => {
        if (document.getElementById("mic-status").innerText.startsWith("ğŸ§")) {
            document.getElementById("mic-status").innerText = "ãƒã‚¤ã‚¯åœæ­¢ä¸­";
        }
    }
} else {
    // å¯¾å¿œã—ã¦ã„ãªã„ãƒ–ãƒ©ã‚¦ã‚¶ã®å ´åˆ
    document.write("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚");
}
</script>
<button onclick="startRec()">ğŸ™ è©±ã™</button>
<p id="mic-status">ãƒã‚¤ã‚¯åœæ­¢ä¸­</p>
""", height=130)

# ===============================
# ãƒãƒ£ãƒƒãƒˆUI
# ===============================
# éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for msg in st.session_state.messages:
    avatar = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æ–°ã—ã„å…¥åŠ›
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¿½åŠ ã—ã€è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("ãƒ¦ãƒƒã‚­ãƒ¼ãŒè€ƒãˆä¸­..."):
            # Geminiã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
            response = st.session_state.chat.send_message(prompt)
            text = response.text
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            st.markdown(text)
            
            # éŸ³å£°å†ç”Ÿã¨å£ãƒ‘ã‚¯åˆ¶å¾¡
            play_tts_with_lip(text)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": text})
