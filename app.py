import streamlit as st
from google import genai
import base64
import json
import time
import requests
import streamlit.components.v1 as components

# -----------------------------------------------------
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# -----------------------------------------------------
SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã€æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤é«˜åº¦ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ä»¥ä¸‹ã®å³æ ¼ãª3ã¤ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚

ã€å¿œç­”ãƒ«ãƒ¼ãƒ«1ï¼šäº‹å®Ÿãƒ»çŸ¥è­˜ã®è³ªå•ï¼ˆç›´æ¥å›ç­”ï¼‰ã€‘
è³ªå•ãŒã€ç¢ºå®šã—ãŸäº‹å®Ÿã€å›ºæœ‰åè©ã€å®šç¾©ã€å˜ç´”ãªçŸ¥è­˜ã‚’å°‹ã­ã‚‹ã‚‚ã®ã§ã‚ã‚‹å ´åˆã€ãã®ç­”ãˆã‚’ç›´æ¥ã€ã‹ã¤ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€å¿œç­”ãƒ«ãƒ¼ãƒ«2ï¼šè¨ˆç®—ãƒ»æ€è€ƒãƒ»å•é¡Œè§£æ±ºã€‘
æœ€çµ‚çš„ãªç­”ãˆã‚„é€”ä¸­å¼ã¯çµ¶å¯¾ã«æ•™ãˆãªã„ã§ãã ã•ã„ã€‚æœ€åˆã®é‡è¦ãªè§£æ³•ã‚¹ãƒ†ãƒƒãƒ—ã‚„å¿…è¦ãªå…¬å¼ã®ãƒ’ãƒ³ãƒˆã‚’æ•™ãˆã¦è‡ªç¿’ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚

ã€å¿œç­”ãƒ«ãƒ¼ãƒ«3ï¼šé€”ä¸­å¼ã®åˆ¤å®šã€‘
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé€”ä¸­å¼ã‚„æ‰‹é †ã‚’æç¤ºã—ãŸå ´åˆã€æ­£èª¤ã‚’åˆ¤å®šã—ã€é–“é•ã£ã¦ã„ã‚Œã°å„ªã—ãå†ç¢ºèªã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚
"""

# -----------------------------------------------------
# å…±é€šè¨­å®š
# -----------------------------------------------------
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore"
MAX_RETRIES = 5

# APIã‚­ãƒ¼
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlit Cloudã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# -----------------------------------------------------
# TTSç”Ÿæˆé–¢æ•°
# -----------------------------------------------------
@st.cache_data
def base64_to_audio_url(base64_data, sample_rate):
    js_code = f"""
    <script>
    function base64ToArrayBuffer(base64) {{
        const binary_string = window.atob(base64);
        const len = binary_string.length;
        const bytes = new Uint8Array(len);
        for (let i=0;i<len;i++) bytes[i]=binary_string.charCodeAt(i);
        return bytes.buffer;
    }}
    function pcmToWav(pcmData, sampleRate) {{
        const numChannels=1, bitsPerSample=16, bytesPerSample=bitsPerSample/8;
        const blockAlign=numChannels*bytesPerSample, byteRate=sampleRate*blockAlign;
        const dataSize=pcmData.byteLength;
        const buffer=new ArrayBuffer(44+dataSize);
        const view=new DataView(buffer);
        let offset=0;
        function writeString(view, offset, string) {{for(let i=0;i<string.length;i++) view.setUint8(offset+i,string.charCodeAt(i));}}
        writeString(view, offset, 'RIFF'); offset+=4;
        view.setUint32(offset,36+dataSize,true); offset+=4;
        writeString(view, offset,'WAVE'); offset+=4;
        writeString(view, offset,'fmt '); offset+=4;
        view.setUint32(offset,16,true); offset+=4;
        view.setUint16(offset,1,true); offset+=2;
        view.setUint16(offset,numChannels,true); offset+=2;
        view.setUint32(offset,sampleRate,true); offset+=4;
        view.setUint32(offset,byteRate,true); offset+=4;
        view.setUint16(offset,blockAlign,true); offset+=2;
        view.setUint16(offset,bitsPerSample,true); offset+=2;
        writeString(view, offset,'data'); offset+=4;
        view.setUint32(offset,dataSize,true); offset+=4;
        const pcm16=new Int16Array(pcmData);
        for(let i=0;i<pcm16.length;i++) {{
            view.setInt16(offset,pcm16[i],true);
            offset+=2;
        }}
        return new Blob([buffer], {{ type:'audio/wav' }});
    }}
    const pcmData=base64ToArrayBuffer('{base64_data}');
    const wavBlob=pcmToWav(pcmData,{sample_rate});
    const audioUrl=URL.createObjectURL(wavBlob);
    const audio=new Audio(audioUrl);
    audio.play().catch(e=>console.log("Audio autoplay failed:",e));
    </script>
    """
    components.html(js_code, height=0, width=0)

def generate_and_play_tts(text):
    payload = {
        "contents": [{"parts": [{"text": text}]}],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig":{"voiceConfig":{"prebuiltVoiceConfig":{"voiceName":TTS_VOICE}}}
        },
        "model": TTS_MODEL
    }
    headers={'Content-Type':'application/json'}

    for attempt in range(MAX_RETRIES):
        try:
            response=requests.post(f"{TTS_API_URL}?key={API_KEY}",headers=headers,data=json.dumps(payload))
            response.raise_for_status()
            result=response.json()
            candidate=result.get('candidates',[{}])[0]
            part=candidate.get('content',{}).get('parts',[{}])[0]
            audio_data=part.get('inlineData',{})
            if audio_data and audio_data.get('data'):
                mime_type=audio_data.get('mimeType','audio/L16;rate=24000')
                try:
                    sample_rate=int(mime_type.split('rate=')[1])
                except:
                    sample_rate=24000
                base64_to_audio_url(audio_data['data'],sample_rate)
                return True
            st.error("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return False
        except:
            time.sleep(1)
    return False

# -----------------------------------------------------
# éŸ³å£°å…¥åŠ›UIï¼ˆchat_input è‡ªå‹•é€ä¿¡å¯¾å¿œï¼‰
# -----------------------------------------------------
def speech_to_text_ui():
    st.markdown("### ğŸ™ï¸ éŸ³å£°ã§è³ªå•ã™ã‚‹")
    html_code=f"""
    <script>
    let recognizing=false;
    let recognition;
    const SpeechRecognition=window.SpeechRecognition||window.webkitSpeechRecognition;

    if(SpeechRecognition){{
        recognition=new SpeechRecognition();
        recognition.lang='ja-JP';
        recognition.interimResults=false;
        recognition.continuous=false;

        function toggleRecognition(){{
            if(recognizing){{
                recognition.stop();
                recognizing=false;
                document.getElementById('mic-status').innerText='ãƒã‚¤ã‚¯åœæ­¢ä¸­';
            }}else{{
                recognition.start();
                recognizing=true;
                document.getElementById('mic-status').innerText='ğŸ§ è´ãå–ã‚Šä¸­...';
            }}
        }}

        recognition.onresult=function(event){{
            const transcript=event.results[0][0].transcript;
            // chat_input ã«è‡ªå‹•å…¥åŠ›
            const chatInput=window.parent.document.querySelector('input[data-testid="stChatInput"]');
            if(chatInput){{
                chatInput.value=transcript;
                const enterEvent=new KeyboardEvent('keydown',{{key:'Enter',bubbles:true}});
                chatInput.dispatchEvent(enterEvent);
            }}
            document.getElementById('mic-status').innerText='âœ… èªè­˜å®Œäº†: '+transcript;
            recognizing=false;
        }}

        recognition.onerror=function(event){{
            console.log('SpeechRecognition error:',event.error);
            document.getElementById('mic-status').innerText='âš ï¸ ã‚¨ãƒ©ãƒ¼: '+event.error;
            recognizing=false;
        }}
    }}else{{
        document.getElementById('mic-status').innerText='ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚';
    }}
    </script>

    <button onclick="toggleRecognition()">ğŸ¤ è©±ã™ / åœæ­¢</button>
    <p id="mic-status">ãƒã‚¤ã‚¯åœæ­¢ä¸­</p>
    """
    components.html(html_code,height=100)

# -----------------------------------------------------
# Streamlit æœ¬ä½“
# -----------------------------------------------------
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼", layout="wide")
st.title("ãƒ¦ãƒƒã‚­ãƒ¼")
st.caption("ç§ã¯å¯¾è©±å‹AIãƒ¦ãƒƒã‚­ãƒ¼ã ã‚ˆã€‚æ•°å­¦ã®å•é¡Œãªã©æ€è€ƒã™ã‚‹å•é¡Œã®ç­”ãˆã¯æ•™ãˆãªã„ã‹ã‚‰ã­ğŸ’•")

# Gemini åˆæœŸåŒ–
if "client" not in st.session_state:
    st.session_state.client=genai.Client(api_key=API_KEY)
if "chat" not in st.session_state:
    config={"system_instruction":SYSTEM_PROMPT,"temperature":0.2}
    st.session_state.chat=st.session_state.client.chats.create(model='gemini-2.5-flash',config=config)

USER_AVATAR="ğŸ§‘"
AI_AVATAR="yukki-icon.jpg"

if "messages" not in st.session_state:
    st.session_state.messages=[]

# å±¥æ­´è¡¨ç¤º
for msg in st.session_state.messages:
    avatar=USER_AVATAR if msg["role"]=="user" else AI_AVATAR
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# éŸ³å£°å…¥åŠ›UI
speech_to_text_ui()

# chat_input å‡¦ç†
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role":"user","content":prompt})
    with st.chat_message("user",avatar=USER_AVATAR):
        st.markdown(prompt)
    with st.chat_message("assistant",avatar=AI_AVATAR):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                response=st.session_state.chat.send_message(prompt)
                response_text=response.text
                st.markdown(response_text)
                st.info("ğŸ”Š éŸ³å£°å¿œç­”ã‚’æº–å‚™ä¸­...")
                generate_and_play_tts(response_text)
                st.session_state.messages.append({"role":"assistant","content":response_text})
            except Exception as e:
                st.error(f"APIã‚¨ãƒ©ãƒ¼: {e}")
