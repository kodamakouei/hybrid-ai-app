import streamlit as st
from google import genai
import base64, json, requests
import streamlit.components.v1 as components
import os

# ===============================
# è¨­å®š
# ===============================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦3ã¤ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚

1ï¸âƒ£ çŸ¥è­˜ãƒ»å®šç¾©ã¯ç›´æ¥ç­”ãˆã‚‹ã€‚
2ï¸âƒ£ æ€è€ƒãƒ»è¨ˆç®—å•é¡Œã¯ç­”ãˆã‚’æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã€‚
3ï¸âƒ£ é€”ä¸­å¼ã‚’è¦‹ã›ã‚‰ã‚ŒãŸå ´åˆã¯æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã€‚
"""
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore"
try:
    API_KEY = st.secrets["GEMINI_API_KEY"] 
except:
    API_KEY = ""

# ===============================
# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒå–å¾— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
# ===============================
@st.cache_data
def get_avatar_images():
    base_names = ["yukki-close", "yukki-open"]
    extensions = [".jpg", ".jpeg"]
    loaded_images = {}
    data_uri_prefix = ""

    for base in base_names:
        for ext in extensions:
            file_name = base + ext
            try:
                with open(file_name, "rb") as f:
                    loaded_images[base] = base64.b64encode(f.read()).decode("utf-8")
                    data_uri_prefix = f"data:image/{'jpeg' if ext in ['.jpg', '.jpeg'] else 'png'};base64,"
                    break
            except FileNotFoundError:
                continue

    if "yukki-close" in loaded_images and "yukki-open" in loaded_images:
        return loaded_images["yukki-close"], loaded_images["yukki-open"], data_uri_prefix, True
    else:
        st.warning("âš ï¸ ã‚¢ãƒã‚¿ãƒ¼ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        placeholder_svg = base64.b64encode(
            f"""<svg width="280" height="280" xmlns="http://www.w3.org/2000/svg"><rect width="100%" height="100%" fill="#f8e7ff"/><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle" font-size="20" fill="#a00" font-family="sans-serif">âŒç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</text></svg>""".encode('utf-8')
        ).decode("utf-8")
        return placeholder_svg, placeholder_svg, "data:image/svg+xml;base64,", False

# ===============================
# éŸ³å£°å†ç”Ÿï¼‹å£ãƒ‘ã‚¯åˆ¶å¾¡
# ===============================
def play_tts_with_lip(text):
    if not API_KEY:
        return
    payload = {
        "contents": [{"parts": [{"text": text}]}],
        "generationConfig": {"responseModalities": ["AUDIO"]},
        "model": TTS_MODEL
    }
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(f"{TTS_API_URL}?key={API_KEY}", headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        result = response.json()
        audio_data_base64 = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
    except Exception as e:
        st.error(f"âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
        return

    st.markdown(f"""
    <script>
    if (window.startTalking) window.startTalking();
    const audio = new Audio('data:audio/wav;base64,{audio_data_base64}');
    audio.autoplay = true;
    audio.onended = () => {{ if (window.stopTalking) window.stopTalking(); }};
    audio.play().catch(e => {{
        console.error("Audio playback failed:", e);
        if (window.stopTalking) window.stopTalking(); 
    }});
    </script>
    """, unsafe_allow_html=True)

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼", layout="wide")

# --- CSSã¨JavaScriptã‚’æ³¨å…¥ ---
img_close_base64, img_open_base64, data_uri_prefix, has_images = get_avatar_images()

st.markdown(f"""
<style>
/* å·¦ã‚«ãƒ©ãƒ ï¼ˆã‚¢ãƒã‚¿ãƒ¼ã®è¦ªï¼‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
[data-testid="stVerticalBlock"]:has(> [data-testid="stHorizontalBlock"] > div:first-child .avatar-wrapper) {{
    position: fixed;
    top: 0;
    left: 0;
    width: 340px; /* ã‚«ãƒ©ãƒ ã®å¹…ã«åˆã‚ã›ã‚‹ */
    height: 100vh;
    display: flex;
    align-items: center;
    justify-content: center;
}}

/* ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã‚’ç”»é¢ä¸‹éƒ¨ã«å›ºå®š */
div[data-testid="stChatInputContainer"] {{
    position: fixed;
    bottom: 0;
    left: 0;
    right: 0;
    width: 100%;
    z-index: 101;
}}

/* å³ã‚«ãƒ©ãƒ ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã«éš ã‚Œãªã„ã‚ˆã†ã«ä¸‹éƒ¨ã«ä½™ç™½ã‚’è¿½åŠ  */
[data-testid="stVerticalBlock"]:has(> [data-testid="stHorizontalBlock"] > div:nth-child(2) .main-content-wrapper) {{
    padding-bottom: 8rem;
}}

.avatar {{
    width: 280px;
    height: 280px;
    border-radius: 16px;
    border: 2px solid #f0a;
    object-fit: cover;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}}
</style>

<script>
const imgCloseBase64 = "{data_uri_prefix}{img_close_base64}";
const imgOpenBase64 = "{data_uri_prefix}{img_open_base64}";
let talkingInterval = null;

window.startTalking = function() {{
    const avatar = document.getElementById('avatar');
    if ({'true' if has_images else 'false'}) {{ 
        let toggle = false;
        if (talkingInterval) clearInterval(talkingInterval);
        talkingInterval = setInterval(() => {{
            avatar.src = toggle ? imgOpenBase64 : imgCloseBase64;
            toggle = !toggle;
        }}, 160);
    }}
}}
window.stopTalking = function() {{
    if (talkingInterval) clearInterval(talkingInterval);
    const avatar = document.getElementById('avatar');
    if ({'true' if has_images else 'false'}) {{
        avatar.src = imgCloseBase64;
    }}
}}
</script>
""", unsafe_allow_html=True)

# --- 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
left_col, right_col = st.columns([1, 2]) # æ¯”ç‡ã‚’èª¿æ•´

with left_col:
    # ã‚¢ãƒã‚¿ãƒ¼ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆCSSã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹ãŸã‚ï¼‰
    st.markdown(f'<div class="avatar-wrapper"><img id="avatar" src="{data_uri_prefix}{img_close_base64}" class="avatar"></div>', unsafe_allow_html=True)

with right_col:
    # å³ã‚«ãƒ©ãƒ ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ©ãƒƒãƒ‘ãƒ¼ã§å›²ã‚€ï¼ˆCSSã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹ãŸã‚ï¼‰
    st.markdown('<div class="main-content-wrapper">', unsafe_allow_html=True)
    
    st.title("ğŸ€ ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆVtuberé¢¨AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼‰")

    # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
    if "client" not in st.session_state:
        st.session_state.client = genai.Client(api_key=API_KEY) if API_KEY else None
    if "chat" not in st.session_state:
        if st.session_state.client:
            config = {"system_instruction": SYSTEM_PROMPT, "temperature": 0.2}
            st.session_state.chat = st.session_state.client.chats.create(model="gemini-2.5-flash", config=config)
        else:
            st.session_state.chat = None
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # éŸ³å£°èªè­˜ãƒœã‚¿ãƒ³
    st.subheader("éŸ³å£°å…¥åŠ›")
    components.html("""
    <div id="mic-container">
        <button onclick="window.parent.startRec()">ğŸ™ è©±ã™</button>
        <p id="mic-status">ãƒã‚¤ã‚¯åœæ­¢ä¸­</p>
    </div>
    <script>
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
        const recognition = new SpeechRecognition();
        recognition.lang = 'ja-JP';
        recognition.continuous = false;
        window.parent.startRec = () => {
            document.getElementById("mic-status").innerText = "ğŸ§ è´ãå–ã‚Šä¸­...";
            recognition.start();
        };
        recognition.onresult = (event) => {
            const text = event.results[0][0].transcript;
            document.getElementById("mic-status").innerText = "âœ… " + text;
            window.parent.postMessage({type: 'SET_CHAT_INPUT', text: text}, '*');
        };
        recognition.onerror = (e) => { document.getElementById("mic-status").innerText = "âš ï¸ ã‚¨ãƒ©ãƒ¼: " + e.error; };
        recognition.onend = () => { if (document.getElementById("mic-status").innerText.startsWith("ğŸ§")) document.getElementById("mic-status").innerText = "ãƒã‚¤ã‚¯åœæ­¢ä¸­"; }
    } else {
        document.getElementById("mic-container").innerHTML = "ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚";
    }
    </script>
    """, height=130)

    # ãƒãƒ£ãƒƒãƒˆUI
    st.subheader("ãƒ¦ãƒƒã‚­ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´")
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"], avatar="ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"):
            st.markdown(msg["content"])
            
    st.markdown('</div>', unsafe_allow_html=True)


# --- ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¨å‡¦ç† ---
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    if st.session_state.chat:
        response = st.session_state.chat.send_message(prompt)
        text = response.text
        st.session_state.messages.append({"role": "assistant", "content": text})
        play_tts_with_lip(text)
    else:
        st.session_state.messages.append({"role": "assistant", "content": "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"})
    st.rerun()

# --- éŸ³å£°èªè­˜ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¸ãƒ†ã‚­ã‚¹ãƒˆã‚’è»¢é€ã™ã‚‹JavaScript ---
components.html("""
<script>
window.addEventListener('message', event => {
    if (event.data.type === 'SET_CHAT_INPUT') {
        const chatInput = window.parent.document.querySelector('textarea[data-testid="stChatInputTextArea"]');
        if (chatInput) {
            chatInput.value = event.data.text;
            chatInput.dispatchEvent(new Event('input', { bubbles: true }));
            const enterEvent = new KeyboardEvent('keydown', { key: 'Enter', bubbles: true, keyCode: 13 });
            chatInput.dispatchEvent(enterEvent);
        }
    }
});
</script>
""", height=0)