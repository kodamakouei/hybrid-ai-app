import streamlit as st
from google import genai
import base64
import json
import requests
import streamlit.components.v1 as components
import os
import time
from google.genai.types import Part
# =========================================
#  ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå…ƒã®ã¾ã¾ï¼‰
# =========================================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã§ãã‚‹ã ã‘ã‹ã¿ç •ã„ã¦ã‚ã‹ã‚Šã‚„ã™ãå¿œç­”ã—ã¦ã
ã ã•ã„ã€‚
1âƒ£çŸ¥è­˜ãƒ»å®šç¾©ç›´æ¥ç­”ãˆã¾ã™ã€‚
2âƒ£æ€è€ƒãƒ»è¨ˆç®—å•é¡Œç­”ãˆã¯æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã‚’ç¤ºã—ã¾ã™ã€‚
3âƒ£é€”ä¸­å¼æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã¾ã™ã€‚
4âƒ£å°‚é–€ç”¨èªã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«åŒºåˆ‡ã‚Šã€å°‚é–€ç”¨èªã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚çŸ¥ã‚‰ãªã‹ã£
ãŸå ´åˆã¯ã€å°å­¦ç”Ÿã«ã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«ã€å›³ã‚„æ“¬éŸ³ãªã©ã®è¡¨ç¾ã€ä¾‹ã¨ãªã‚‹é¢ç™½ã„æ–‡ã‚’ç©æ¥µçš„ã«ä½¿ã£
ã¦ãã®å ´ã§èª¬æ˜ã—ã¾ã™ã€‚
5âƒ£èª¬æ˜ã¯ç •ã‘ãŸä¼šè©±å£èª¿ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
6âƒ£ã„ããªã‚Šã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨éƒ¨å‡ºã•ãªã„ã§ãã ã•ã„ã€‚ã€Œã“ã“ã§ã€ï½ï½ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã¾ã™ã‹ï¼Ÿã€
ã®ã¨ã“ã‚ã§ã„ã£ãŸã‚“è¡¨ç¤ºã™ã‚‹ã®ã‚’ã‚„ã‚ã¦ãã ã•ã„ã€‚
7âƒ£å°‚é–€ç”¨èªã‚„é€”ä¸­ã®éç¨‹ã®åˆ†ã‹ã‚‰ãªã„éƒ¨åˆ†ã«ã¤ã„ã¦èª¬æ˜ã•ã‚ŒãŸã¨ãã¯ã€ã§ãã‚‹ã ã‘è©³ã—ãèª¬æ˜
ã—ã¦ãã ã•ã„ã€‚ã ã‹ã‚‰ã¨è¨€ã£ã¦ãã®èª¬æ˜ã‚’èã„ã¦ã„ã‚‹äººã«èª­ã‚€ã®ã‚’é£½ãã•ã›ã¦ã—ã¾ã†ã‚ˆã†ãªèª¬
æ˜ã¯ã‚„ã‚ã¦ãã ã•ã„ã€‚

"""

# =========================================
# APIã‚­ãƒ¼èª­ã¿è¾¼ã¿
# =========================================
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = ""

# =========================================
# TTSï¼ˆéŸ³å£°ç”Ÿæˆï¼‰é–¢æ•°
# =========================================
def generate_and_store_tts(text):
    """
    TTSãƒ¢ãƒ‡ãƒ«ã®äº’æ›æ€§ãƒã‚§ãƒƒã‚¯ã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«åã‚’å¤‰æ›´ã—ã€ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å¼·åŒ–
    """
    if not text:
        return None

    try:
        client = genai.Client(api_key=API_KEY)

        # â˜…ãƒ¢ãƒ‡ãƒ«åã‚’ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã¨åŒã˜å®‰å®šç‰ˆã«å¤‰æ›´ (äº’æ›æ€§ç¢ºèªã®ãŸã‚)
        response = client.models.generate_content(
            model="gemini-2.5-flash", 
            contents=[text],
            config={
                # â˜… audio_config ã¯ãã®ã¾ã¾æ®‹ã—ã€å‹•ä½œã™ã‚‹ã‹ç¢ºèª
                "audio_config": {
                    "voice_name": "ja-JP-Neural2-B",
                    "speaking_rate": 1.05
                }
            }
        )

        audio_data = None
        for part in response.parts:
            # safety_ratings ã‚„ blocked ãŒãªã„ã‹ç¢ºèª
            if hasattr(part, "safety_ratings") and part.safety_ratings:
                print(f"å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã«ã‚ˆã‚Šå¿œç­”ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ: {part.safety_ratings}")
                return None
                
            if hasattr(part, "data") and part.data:
                audio_data = part.data
                break

        if not audio_data:
            print("éŸ³å£°ãƒ‘ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…¨å¿œç­”ãƒ‘ãƒ¼ãƒ„:")
            print(response.parts) # ã™ã¹ã¦ã®ãƒ‘ãƒ¼ãƒ„ã‚’å‡ºåŠ›ã—ã¦ã€TTSã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            return None

        audio_bytes = audio_data
        audio_dir = "generated_audio"
        os.makedirs(audio_dir, exist_ok=True)
        audio_path = os.path.join(
            audio_dir,
            f"tts_{int(time.time())}.wav"
        )

        with open(audio_path, "wb") as f:
            f.write(audio_bytes)

        print("TTS éŸ³å£°ç”ŸæˆæˆåŠŸ:", audio_path)
        return audio_path

    except Exception as e:
        # â˜…ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›
        print("TTSç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°:")
        print(f"ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥: {type(e).__name__}")
        print(f"ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {e}")
        return None


# =========================================
# Streamlit UI è¨­å®š
# =========================================
st.set_page_config(
    page_title="ãƒ¦ãƒƒã‚­ãƒ¼",
    layout="wide"   # â˜…ã‚µã‚¤ãƒ‰ãƒãƒ¼ãŒç„¡ã„å‰æã§å…¨å¹…ä½¿ç”¨
)

# ---- ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ----
if "client" not in st.session_state:
    st.session_state.client = genai.Client(api_key=API_KEY) if API_KEY else None

if "chat" not in st.session_state:
    if st.session_state.client:
        config = {
            "system_instruction": SYSTEM_PROMPT,
            "temperature": 0.2
        }
        st.session_state.chat = st.session_state.client.chats.create(
            model="gemini-2.5-flash",
            config=config
        )
    else:
        st.session_state.chat = None

if "messages" not in st.session_state:
    st.session_state.messages = []

if "audio_to_play" not in st.session_state:
    st.session_state.audio_to_play = None


# =========================================
# ãƒ¡ã‚¤ãƒ³ç”»é¢ UI
# =========================================
st.title("ğŸ€ ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆç–‘ä¼¼æ•™å¸«ï¼‰")
st.caption("çŸ¥è­˜ã¯ç­”ãˆã€æ€è€ƒã¯è§£æ³•ã‚¬ã‚¤ãƒ‰ã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚")

# ---------- ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ----------
st.subheader("ç”»åƒã‚’é€ã£ã¦è³ªå•ã™ã‚‹")

uploaded_image = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã¿ã‚ˆã†", type=["jpg", "jpeg", "png"])

if uploaded_image:
    st.image(uploaded_image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", width=300)
    uploaded_bytes = uploaded_image.read()
else:
    uploaded_bytes = None

# ---------- ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°å…¥åŠ› UIï¼ˆWeb Audio APIï¼‰ ----------
components.html("""
<script>
function startVoiceRecognition() {
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "ja-JP";
    recognition.onresult = function(event) {
        const text = event.results[0][0].transcript;
        window.parent.postMessage({type: 'stt-result', text: text}, '*');
    };
    recognition.start();
}
</script>

<button onclick="startVoiceRecognition()" style="
    background-color:#ff8dc7;
    border:none;
    padding:12px 18px;
    border-radius:8px;
    color:white;
    font-size:16px;
    cursor:pointer;
    margin-bottom:10px;
">
ğŸ¤ éŸ³å£°ã§è©±ã™
</button>
""", height=80)

# ---------- éŸ³å£°ã§èªè­˜ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®å—ä¿¡ ----------
components.html("""
<script>
window.addEventListener("message", (event) => {
    if (event.data.type === "stt-result") {
        const text = event.data.text;
        window.parent.postMessage({ type: "streamlit:setChatInputValue", value: text }, "*");
        window.parent.postMessage({ type: "streamlit:focusChatInput" }, "*");
    }
});
</script>
""", height=0)

# ---------- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ ----------
st.subheader("ãƒ¦ãƒƒã‚­ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´")

for msg in st.session_state.messages:
    avatar_icon = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar_icon):
        st.markdown(msg["content"])

# ---------- ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆå…¥åŠ› ----------
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„â€¦"):
    
    # å±¥æ­´ã¸è¿½åŠ  (ãƒ¦ãƒ¼ã‚¶ãƒ¼)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Geminiã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
    contents_to_send = []
    
    # 1. ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
    contents_to_send.append(prompt) 
    
    # 2. ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¿½åŠ 
    if uploaded_image and uploaded_bytes:
        
        # â˜…â˜…â˜… ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: Part.from_bytes() ã‚’ä½¿ã£ã¦ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æ˜ç¤ºçš„ã« Part ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ â˜…â˜…â˜…
        try:
            image_part = Part.from_bytes(
                data=uploaded_bytes,
                mime_type=uploaded_image.type
            )
            contents_to_send.append(image_part)
        except Exception as e:
            # Partå¤‰æ›ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            print(f"ç”»åƒãƒ‡ãƒ¼ã‚¿ã®Partå¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
    # ---- Gemini ã¸é€ä¿¡ ----
    if st.session_state.chat:
        
        # message_content ã¯å¸¸ã« contents_to_send ãƒªã‚¹ãƒˆå…¨ä½“
        message_content = contents_to_send 
        
        try:
            # ä¿®æ­£å¾Œã®ãƒ­ã‚¸ãƒƒã‚¯: ãƒªã‚¹ãƒˆã«ã¯ (str ã¾ãŸã¯ Part) ã®çµ„ã¿åˆã‚ã›ãŒå«ã¾ã‚Œã‚‹
            response = st.session_state.chat.send_message(message_content)
        except Exception as e:
            # é€ä¿¡æ™‚ã®ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã€ãƒ­ã‚°ã«å‡ºåŠ›
            response_text = f"Gemini APIé€ä¿¡ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            print(response_text)
            
        else:
            response_text = response.text if hasattr(response, "text") else str(response)
    else:
        response_text = "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚å¿œç­”ã§ãã¾ã›ã‚“ã€‚"

    # å±¥æ­´ã«è¿½åŠ  (ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ)
    st.session_state.messages.append({"role": "assistant", "content": response_text})

    # TTSç”Ÿæˆ
    audio_path = generate_and_store_tts(response_text)
    if audio_path:
        st.session_state.audio_to_play = audio_path
        
    # Streamlitã®å†å®Ÿè¡Œ (st.rerun) å‰ã«ã€æ¬¡ã®å…¥åŠ›ã®ãŸã‚ã«ç”»åƒã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ãŒé‡è¦
    # Streamlitã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®çŠ¶æ…‹ã¯ç¶­æŒã•ã‚Œãªã„ãŸã‚ã€
    # ã“ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯ãƒ‡ãƒãƒƒã‚°ç›®çš„ã§æ®‹ã—ã¾ã™ãŒã€æ ¹æœ¬çš„ã«ã¯ st.chat_input ã®å†å®Ÿè¡Œã‚’é˜²ããŸã‚ã« st.rerun ãŒå¿…è¦ã§ã™ã€‚

    # â˜…â˜…â˜… è¿½è¨˜: Geminiãƒãƒ£ãƒƒãƒˆã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€ã‚¨ãƒ©ãƒ¼ã®åŸå› ã¨ãªã‚‹å†åˆ©ç”¨ã‚’é˜²ã â˜…â˜…â˜…
    # ãŸã ã—ã€ã“ã‚Œã¯æ—¢å­˜ã®ä¼šè©±å±¥æ­´ãŒå¤±ã‚ã‚Œã‚‹å‰¯ä½œç”¨ãŒã‚ã‚‹ãŸã‚ã€æ¨å¥¨ã¯ã§ãã¾ã›ã‚“ã€‚
    # ä»£ã‚ã‚Šã«ã€ç°¡æ½”ãªãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã«ã®ã¿å±¥æ­´ã‚’è¿½åŠ ã—ã€rerunå¾Œã¯ç”»åƒãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚

    # ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãŸå ´åˆã€æ¬¡å›å†å®Ÿè¡Œæ™‚ã«ç”»åƒãŒå†é€ä¿¡ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã®å‡¦ç½®
    if uploaded_image:
        uploaded_image = None # uploaded_imageã®å‚ç…§ã‚’ãƒªã‚»ãƒƒãƒˆ

    st.rerun()
# ---------- éŸ³å£°å†ç”Ÿ ----------
if st.session_state.audio_to_play:
    st.audio(st.session_state.audio_to_play, format="audio/wav")
