import streamlit as st
from google import genai
import base64, json, requests
import streamlit.components.v1 as components

# ===============================
# è¨­å®š
# ===============================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦3ã¤ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚

1ï¸âƒ£ çŸ¥è­˜ãƒ»å®šç¾©ã¯ç›´æ¥ç­”ãˆã‚‹ã€‚
2ï¸âƒ£ æ€è€ƒãƒ»è¨ˆç®—å•é¡Œã¯ç­”ãˆã‚’æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã€‚
3ï¸âƒ£ é€”ä¸­å¼ã‚’è¦‹ã›ã‚‰ã‚ŒãŸå ´åˆã¯æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã€‚
"""
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore"
API_KEY = st.secrets["GEMINI_API_KEY"]

# ===============================
# ã‚¢ãƒã‚¿ãƒ¼è¡¨ç¤ºï¼ˆç°¡ç•¥ï¼‰
# ===============================
def show_avatar():
    img_close = base64.b64encode(open("yukki-close.jpg", "rb").read()).decode("utf-8")
    img_open = base64.b64encode(open("yukki-open.jpg", "rb").read()).decode("utf-8")

    components.html(f"""
    <style>
    .avatar {{
        width: 280px; height: 280px; border-radius: 16px;
        border: 2px solid #f0a; object-fit: contain;
    }}
    </style>
    <div style="text-align:center;">
      <img id="avatar" src="data:image/png;base64,{img_close}" class="avatar">
    </div>
    <script>
    let talkingInterval=null;
    function startTalking() {{
        let toggle=false;
        const img=document.getElementById('avatar');
        talkingInterval=setInterval(()=>{{
            img.src=toggle?"data:image/png;base64,{img_open}":"data:image/png;base64,{img_close}";
            toggle=!toggle;
        }},160);
    }}
    function stopTalking() {{
        clearInterval(talkingInterval);
        document.getElementById('avatar').src="data:image/png;base64,{img_close}";
    }}
    </script>
    """, height=340)

# ===============================
# éŸ³å£°å†ç”Ÿï¼‹å£ãƒ‘ã‚¯
# ===============================
def play_tts_with_lip(text):
    payload = {
        "contents": [{"parts": [{"text": text}]}],
        "generationConfig": {"responseModalities": ["AUDIO"],
                             "speechConfig": {"voiceConfig": {"prebuiltVoiceConfig": {"voiceName": TTS_VOICE}}}},
        "model": TTS_MODEL
    }
    headers = {"Content-Type": "application/json"}
    res = requests.post(f"{TTS_API_URL}?key={API_KEY}", headers=headers, data=json.dumps(payload)).json()
    try:
        audio_data = res["contents"][0]["parts"][0]["inlineData"]["data"]
    except Exception:
        st.error("âŒ éŸ³å£°ç”Ÿæˆå¤±æ•—")
        st.json(res)
        return
    audio_bytes = base64.b64decode(audio_data)

    # JSåˆ¶å¾¡
    components.html("""
    <script>
      if (window.startTalking) startTalking();
      setTimeout(()=>{ if(window.stopTalking) stopTalking(); },7000);
    </script>
    """, height=0)
    st.audio(audio_bytes, format="audio/wav")

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆéŸ³å£°å…¥åŠ›å®‰å…¨ç‰ˆï¼‰", layout="wide")
st.title("ğŸ€ ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆVtuberé¢¨ãƒ»å®‰å…¨éŸ³å£°èªè­˜ï¼‰")

show_avatar()

# ===============================
# Speech-to-text (JSâ†’Python)
# ===============================
st.markdown("### ğŸ™ éŸ³å£°å…¥åŠ›")
components.html("""
<script>
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
let recognition;

if (SpeechRecognition) {
    recognition = new SpeechRecognition();
    recognition.lang = 'ja-JP';
    recognition.continuous = false;
    recognition.interimResults = false;

    function startRec() {
        document.getElementById("mic-status").innerText = "ğŸ§ è´ãå–ã‚Šä¸­...";
        recognition.start();
    }

    recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        document.getElementById("mic-status").innerText = "âœ… " + text;
        fetch("/_stcore/mic_result", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text })
        });
    };

    recognition.onerror = (e) => {
        document.getElementById("mic-status").innerText = "âš ï¸ " + e.error;
    };
} else {
    document.write("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚");
}
</script>
<button onclick="startRec()">ğŸ™ è©±ã™</button>
<p id="mic-status">ãƒã‚¤ã‚¯åœæ­¢ä¸­</p>
""", height=130)

# ===============================
# JSã‹ã‚‰ã®POSTã‚’å—ã‘å–ã‚‹ (custom endpoint)
# ===============================
from streamlit.runtime.scriptrunner import add_script_run_ctx
from streamlit.web.server.websocket_headers import _get_websocket_headers
from streamlit.web.server.routes import Route, serve_path
import threading
import tornado.web

class MicHandler(tornado.web.RequestHandler):
    def post(self):
        data = json.loads(self.request.body)
        text = data.get("text", "")
        st.session_state["speech_text"] = text

# Tornado ã«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¿½åŠ 
route = Route("/_stcore/mic_result", MicHandler)
serve_path.routes.append(route)

# ===============================
# ãƒãƒ£ãƒƒãƒˆç”»é¢
# ===============================
if "client" not in st.session_state:
    st.session_state.client = genai.Client(api_key=API_KEY)
if "chat" not in st.session_state:
    cfg = {"system_instruction": SYSTEM_PROMPT, "temperature": 0.2}
    st.session_state.chat = st.session_state.client.chats.create(model="gemini-2.5-flash", config=cfg)
if "messages" not in st.session_state:
    st.session_state.messages = []

# éŸ³å£°çµæœãŒæ¥ãŸã‚‰chat_inputã«è‡ªå‹•åæ˜ 
speech_text = st.session_state.pop("speech_text", "")
prompt = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...", value=speech_text)

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(prompt)
    with st.chat_message("assistant", avatar="yukki-close.jpg"):
        with st.spinner("ãƒ¦ãƒƒã‚­ãƒ¼ãŒè€ƒãˆä¸­..."):
            resp = st.session_state.chat.send_message(prompt)
            text = resp.text
            st.markdown(text)
            play_tts_with_lip(text)
            st.session_state.messages.append({"role": "assistant", "content": text})
