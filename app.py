import streamlit as st
from google import genai
import base64, json, requests
import streamlit.components.v1 as components
import os
import time
from PIL import Image
import io
import fitz  # PyMuPDF

# ===============================
# è¨­å®š
# ===============================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯æ•™è‚²çš„ãªç›®çš„ã‚’æŒã¤ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã§ãã‚‹ã ã‘ã‹ã¿ç •ã„ã¦ã‚ã‹ã‚Šã‚„ã™ãå¿œç­”ã—ã¦ã
ã ã•ã„ã€‚
1âƒ£çŸ¥è­˜ãƒ»å®šç¾©ç›´æ¥ç­”ãˆã¾ã™ã€‚
2âƒ£æ€è€ƒãƒ»è¨ˆç®—å•é¡Œç­”ãˆã¯æ•™ãˆãšã€è§£æ³•ã®ãƒ’ãƒ³ãƒˆã®ã¿ã‚’ç¤ºã—ã¾ã™ã€‚
3âƒ£é€”ä¸­å¼æ­£èª¤ã‚’åˆ¤å®šã—ã€å„ªã—ãå°ãã¾ã™ã€‚
4âƒ£å°‚é–€ç”¨èªã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«åŒºåˆ‡ã‚Šã€å°‚é–€ç”¨èªã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚çŸ¥ã‚‰ãªã‹ã£
ãŸå ´åˆã¯ã€å°å­¦ç”Ÿã«ã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«ã€å›³ã‚„æ“¬éŸ³ãªã©ã®è¡¨ç¾ã€ä¾‹ã¨ãªã‚‹é¢ç™½ã„æ–‡ã‚’ç©æ¥µçš„ã«ä½¿ã£
ã¦ãã®å ´ã§èª¬æ˜ã—ã¾ã™ã€‚
5âƒ£èª¬æ˜ã¯ç •ã‘ãŸä¼šè©±å£èª¿ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
6âƒ£ã„ããªã‚Šã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨éƒ¨å‡ºã•ãªã„ã§ãã ã•ã„ã€‚ã€Œã“ã“ã§ã€ï½ï½ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã¾ã™ã‹ï¼Ÿã€
ã®ã¨ã“ã‚ã§ã„ã£ãŸã‚“è¡¨ç¤ºã™ã‚‹ã®ã‚’ã‚„ã‚ã¦ãã ã•ã„ã€‚
7âƒ£å°‚é–€ç”¨èªã‚„é€”ä¸­ã®éç¨‹ã®åˆ†ã‹ã‚‰ãªã„éƒ¨åˆ†ã«ã¤ã„ã¦èª¬æ˜ã•ã‚ŒãŸã¨ãã¯ã€ã§ãã‚‹ã ã‘è©³ã—ãèª¬æ˜
ã—ã¦ãã ã•ã„ã€‚ã ã‹ã‚‰ã¨è¨€ã£ã¦ãã®èª¬æ˜ã‚’èã„ã¦ã„ã‚‹äººã«èª­ã‚€ã®ã‚’é£½ãã•ã›ã¦ã—ã¾ã†ã‚ˆã†ãªèª¬
æ˜ã¯ã‚„ã‚ã¦ãã ã•ã„ã€‚
"""
# --- å…±é€šè¨­å®š ---
TTS_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
TTS_MODEL = "gemini-2.5-flash-preview-tts"
TTS_VOICE = "Kore"
MAX_RETRIES = 5
SIDEBAR_FIXED_WIDTH = "450px"

# --- APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ ---
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except (KeyError, AttributeError):
    API_KEY = ""

# ===============================
# ã‚¢ãƒã‚¿ãƒ¼ç”»åƒå–å¾— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
# ===============================
@st.cache_data
def get_avatar_image():
    base_name = "yukki-static"
    extensions = [".jpg", ".jpeg", ".png"]
    loaded_image = None
    data_uri_prefix = ""
    for ext in extensions:
        file_name = base_name + ext
        if os.path.exists(file_name):
            with open(file_name, "rb") as f:
                loaded_image = base64.b64encode(f.read()).decode("utf-8")
                data_uri_prefix = f"data:image/{'jpeg' if ext in ['.jpg', '.jpeg'] else 'png'};base64,"
                break
    if loaded_image:
        return loaded_image, data_uri_prefix, True
    else:
        placeholder_svg = base64.b64encode(
            f"""<svg width="400" height="400" xmlns="http://www.w3.org/2000/svg"><rect width="100%" height="100%" fill="#f8e7ff"/><text x="50%" y="45%" dominant-baseline="middle" text-anchor="middle" font-size="28" fill="#a00" font-family="sans-serif">âŒç”»åƒãªã—</text><text x="50%" y="55%" dominant-baseline="middle" text-anchor="middle" font-size="20" fill="#a00" font-family="sans-serif">{base_name}.jpg/jpeg/png</text></svg>""".encode('utf-8')
        ).decode("utf-8")
        return placeholder_svg, "data:image/svg+xml;base64,", False

# ===============================
# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
# ===============================
def generate_and_store_tts(text):
    if not API_KEY:
        st.session_state.audio_to_play = None
        return
    payload = {
        "contents": [{"parts": [{"text": text}]}],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig": {"voiceConfig": {"prebuiltVoiceConfig": {"voiceName": TTS_VOICE}}},
        },
        "model": TTS_MODEL,
    }
    headers = {'Content-Type': 'application/json'}
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(f"{TTS_API_URL}?key={API_KEY}", headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            result = response.json()
            st.session_state.audio_to_play = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
            return
        except requests.exceptions.HTTPError as e:
            if response.status_code in [429, 503] and attempt < MAX_RETRIES - 1:
                time.sleep(2 ** attempt)
                continue
            print(f"API Error (HTTP {response.status_code}) or final attempt failed: {e}")
            break
        except Exception as e:
            print(f"Error generating TTS: {e}")
            break
    st.session_state.audio_to_play = None

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="ãƒ¦ãƒƒã‚­ãƒ¼", layout="wide")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«CSSã®é©ç”¨ ---
st.markdown(f"""
<style>
header {{ visibility: hidden; }}
[data-testid="stSidebarContent"] > div:first-child {{ width: {SIDEBAR_FIXED_WIDTH} !important; display: flex; flex-direction: column; align-items: center; justify-content: flex-start; }}
.avatar {{ width: 400px; height: 400px; border-radius: 16px; object-fit: cover; margin: 0 auto; }}
[data-testid="stSidebarContent"] {{ width: {SIDEBAR_FIXED_WIDTH} !important; min-width: {SIDEBAR_FIXED_WIDTH} !important; max-width: {SIDEBAR_FIXED_WIDTH} !important; }}
[data-testid="stSidebarCollapseButton"] {{ display: none !important; }}
section[data-testid="stSidebar"] {{ width: {SIDEBAR_FIXED_WIDTH} !important; min-width: {SIDEBAR_FIXED_WIDTH} !important; max-width: {SIDEBAR_FIXED_WIDTH} !important; background-color: #FFFFFF !important; }}
.main {{ background-color: #FFFFFF !important; }}
</style>
""", unsafe_allow_html=True)

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
if "client" not in st.session_state:
    st.session_state.client = genai.Client(api_key=API_KEY) if API_KEY else None
if "chat" not in st.session_state:
    if st.session_state.client:
        config = {"system_instruction": SYSTEM_PROMPT, "temperature": 0.2}
        st.session_state.chat = st.session_state.client.chats.create(model="gemini-2.5-flash", config=config)
    else:
        st.session_state.chat = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "audio_to_play" not in st.session_state:
    st.session_state.audio_to_play = None
if "uploaded_file" not in st.session_state:
    st.session_state.uploaded_file = None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    img_base64, data_uri_prefix, has_image = get_avatar_image()
    if not has_image:
        st.warning("âš ï¸ ã‚¢ãƒã‚¿ãƒ¼ç”»åƒ(yukki-static.jpg/png)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.markdown(f'<img id="avatar" src="{data_uri_prefix}{img_base64}" class="avatar">', unsafe_allow_html=True)

# --- éŸ³å£°å†ç”Ÿ ---
if st.session_state.audio_to_play:
    js_code = f"""
    <script>
        function base64ToArrayBuffer(base64) {{ const binary_string = window.atob(base64); const len = binary_string.length; const bytes = new Uint8Array(len); for (let i = 0; i < len; i++) {{ bytes[i] = binary_string.charCodeAt(i); }} return bytes.buffer; }}
        function writeString(view, offset, string) {{ for (let i = 0; i < string.length; i++) {{ view.setUint8(offset + i, string.charCodeAt(i)); }} }}
        function pcmToWav(pcmData, sampleRate) {{ const numChannels = 1; const bitsPerSample = 16; const bytesPerSample = bitsPerSample / 8; const blockAlign = numChannels * bytesPerSample; const byteRate = sampleRate * blockAlign; const dataSize = pcmData.byteLength; const buffer = new ArrayBuffer(44 + dataSize); const view = new DataView(buffer); let offset = 0; writeString(view, offset, 'RIFF'); offset += 4; view.setUint32(offset, 36 + dataSize, true); offset += 4; writeString(view, offset, 'WAVE'); offset += 4; writeString(view, offset, 'fmt '); offset += 4; view.setUint32(offset, 16, true); offset += 4; view.setUint16(offset, 1, true); offset += 2; view.setUint16(offset, numChannels, true); offset += 2; view.setUint32(offset, sampleRate, true); offset += 4; view.setUint32(offset, byteRate, true); offset += 4; view.setUint16(offset, blockAlign, true); offset += 2; view.setUint16(offset, bitsPerSample, true); offset += 2; writeString(view, offset, 'data'); offset += 4; view.setUint32(offset, dataSize, true); offset += 4; const pcm16 = new Int16Array(pcmData); for (let i = 0; i < pcm16.length; i++) {{ view.setInt16(offset, pcm16[i], true); offset += 2; }} return new Blob([buffer], {{ type: 'audio/wav' }}); }}
        const base64AudioData = '{st.session_state.audio_to_play}'; const sampleRate = 24000; const pcmData = base64ToArrayBuffer(base64AudioData); const wavBlob = pcmToWav(pcmData, sampleRate); const audioUrl = URL.createObjectURL(wavBlob); const audio = new Audio(audioUrl); audio.autoplay = true; audio.onended = () => {{ URL.revokeObjectURL(audioUrl); }}; audio.play().catch(e => console.error("Audio playback failed:", e));
    </script>
    """
    components.html(js_code, height=0, width=0)
    st.session_state.audio_to_play = None

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
st.title("ğŸ€ ãƒ¦ãƒƒã‚­ãƒ¼ï¼ˆç–‘ä¼¼æ•™å¸«ï¼‰")
st.caption("çŸ¥è­˜ã¯ç­”ãˆã€æ€è€ƒã¯è§£æ³•ã‚¬ã‚¤ãƒ‰ã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
uploaded_file = st.file_uploader(
    "ç”»åƒã‚„PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è³ªå•ã§ãã¾ã™",
    type=['png', 'jpg', 'jpeg', 'pdf'],
    help="ã“ã“ã«ç”»åƒã‚„PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚"
)
if uploaded_file:
    st.session_state.uploaded_file = uploaded_file

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
if st.session_state.uploaded_file:
    file_type = st.session_state.uploaded_file.type
    if "pdf" in file_type:
        st.info(f"ğŸ“„ PDFã€Œ{st.session_state.uploaded_file.name}ã€ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")
    else:
        st.image(st.session_state.uploaded_file, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", width=300)

# éŸ³å£°èªè­˜ãƒœã‚¿ãƒ³
st.subheader("éŸ³å£°å…¥åŠ›")
components.html("""
<div id="mic-container" style="padding: 10px 0;"><button onclick="window.parent.startRec()" style="background-color: #ff69b4; color: white; border: none; padding: 10px 20px; border-radius: 8px; cursor: pointer; font-size: 16px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">ğŸ™ è©±ã™</button><p id="mic-status" style="margin-top: 10px;">ãƒã‚¤ã‚¯åœæ­¢ä¸­</p></div>
<script>
function sendTextToStreamlit(text) { window.parent.postMessage({ type: 'SET_CHAT_INPUT', text: text }, '*'); }
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
if (SpeechRecognition) {
    const recognition = new SpeechRecognition(); recognition.lang = 'ja-JP'; recognition.continuous = false; recognition.interimResults = false;
    window.parent.startRec = () => { document.getElementById("mic-status").innerText = "ğŸ§ è´ãå–ã‚Šä¸­..."; recognition.start(); };
    recognition.onresult = (event) => { const text = event.results[0][0].transcript; document.getElementById("mic-status").innerText = "âœ… " + text; sendTextToStreamlit(text); };
    recognition.onerror = (e) => { document.getElementById("mic-status").innerText = "âš ï¸ ã‚¨ãƒ©ãƒ¼: " + e.error; };
    recognition.onend = () => { if (document.getElementById("mic-status").innerText.startsWith("ğŸ§")) { document.getElementById("mic-status").innerText = "ãƒã‚¤ã‚¯åœæ­¢ä¸­"; } };
} else { document.getElementById("mic-container").innerHTML = "ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚"; }
</script>
""", height=130)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
st.subheader("ãƒ¦ãƒƒã‚­ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´")
for msg in st.session_state.messages:
    avatar_icon = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar_icon):
        st.markdown(msg["content"])

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¨AIå¿œç­”ç”Ÿæˆ
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("ãƒ¦ãƒƒã‚­ãƒ¼ãŒæ€è€ƒä¸­..."):
            if st.session_state.chat:
                try:
                    content_parts = [prompt]
                    if st.session_state.uploaded_file:
                        file_bytes = st.session_state.uploaded_file.getvalue()
                        file_type = st.session_state.uploaded_file.type
                        if "pdf" in file_type:
                            pdf_doc = fitz.open(stream=file_bytes, filetype="pdf")
                            for page_num in range(len(pdf_doc)):
                                page = pdf_doc.load_page(page_num)
                                pix = page.get_pixmap()
                                img_bytes = pix.tobytes("png")
                                content_parts.append(Image.open(io.BytesIO(img_bytes)))
                        else:
                            content_parts.append(Image.open(io.BytesIO(file_bytes)))
                        
                        # â˜…â˜…â˜… ä½¿ç”¨å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚¯ãƒªã‚¢ â˜…â˜…â˜…
                        st.session_state.uploaded_file = None

                    response = st.session_state.chat.send_message(content_parts)
                    text = response.text
                    st.markdown(text)
                    generate_and_store_tts(text)
                    st.session_state.messages.append({"role": "assistant", "content": text})

                except Exception as e:
                    error_msg = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
            else:
                error_msg = "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"
                st.warning(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})
    
    st.rerun()

# éŸ³å£°èªè­˜ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã¸ã®è»¢é€
components.html("""
<script>
window.addEventListener('message', event => {
    if (event.data.type === 'SET_CHAT_INPUT') {
        const chatInput = window.parent.document.querySelector('textarea[data-testid="stChatInputTextArea"]');
        if (chatInput) {
            chatInput.value = event.data.text;
            chatInput.dispatchEvent(new Event('input', { bubbles: true }));
            const enterEvent = new KeyboardEvent('keydown', { key: 'Enter', bubbles: true, keyCode: 13 });
            chatInput.dispatchEvent(enterEvent);
        }
    }
});
</script>
""", height=0)